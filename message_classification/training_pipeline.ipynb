{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import necessary libraries\n",
    "\n",
    "Import pandas as pd, numpy as np and seaborn as sns\n",
    "Furthermore, import Pipeline from sklearn.pipeline, RandomForestClassifier from sklearn.ensemble and train_test_split from sklearn.model_selection\n",
    "\n",
    "Import accuracy_score, f1_score, precision_score, hamming_loss and confusion_matrix from sklearn.metrics and joblib from sklearn.externals \n",
    "\n",
    "Finally, import CountVectorizer and TfidfTransformer from sklearn.feature_extraction.text and pplot_cm from conf_matrix (this script should be in your local repo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n",
    "Load your previously saved csv dataframe using pandas' read_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot label frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the seaborn color palette to \"deep\" using sns.set().\n",
    "Then, plot the label frequencies using sns.countplot() on the column \"sentiment\" (or what ever you have called it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load stopwords\n",
    "\n",
    "Use stop_words to remove less-meaningful words. The logic of removing stop words has to do with the fact that these words don't carry a lot of meaning, and they appear a lot in most text. We have provided you with a list of common German stopwords ('data/stopwords_german.txt'). Import the packages io and unidecode first, then use io.open() and readlines() to save the words contained in the .txt file to a list. \n",
    "\n",
    "Call the python string function strip() and unidecode's unidecode() on every element in the resulting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also add your own stopwords in this step using append()\n",
    "...\n",
    "\n",
    "stopwords = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data for training\n",
    "\n",
    "To train and evaluate the model, we split the data into a training set and a test set using train_test_split(), the arguments  being the text column, the label/sentiment column, a test set size (test_size=0.1 for 10%, test_size=0.3 for 30%, etc.) and a integer of your choice as random_state.\n",
    "\n",
    "You can then call .shape on the resulting sets to see their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up ML pipeline\n",
    "\n",
    "Instantiate a pipeline by adding 3 steps: a CountVectorizer() 'vect', a TfidfTransformer() 'tfidf' and a RandomForestClassifier() 'rf'.\n",
    "\n",
    "The Countvectorizer helps us to create numerical values from text by counting the inherent tokens. Pass analyzer='word', strip_accents='unicode' and lowercase=True. Pass your list of stopwords as stop_words.\n",
    "\n",
    "The arguments for the TfidfTransformer are use_idf=True and smooth_idf=True.\n",
    "\n",
    "Fit your pipeline to the training data by calling .fit() on the pipeline object and passing the training texts and training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'vect',\n",
    "        ...\n",
    "    ),\n",
    "    (\n",
    "        'tfidf',\n",
    "        ...\n",
    "    ),\n",
    "    (\n",
    "        'rf',\n",
    "        ...\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipeline to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score model\n",
    "\n",
    "We have provided you with a function to score your model using the test texts and labels. In case of encoding issues calling .values.astype('U') on the texts before passing them to your pipeline might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(true, pred):\n",
    "    print('Accuracy:', accuracy_score(true, pred))\n",
    "    print('F1:', f1_score(true, pred, average='weighted'))\n",
    "    print('Precision:', precision_score(true, pred, average='weighted'))\n",
    "    print('Hamming loss', hamming_loss(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot confusion matrix\n",
    "\n",
    "To quickly plot a confusion matrix, use the provided function pplot_cm and pass the same arguments as with score_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a confucion matrix to visualize true positives, true negatives, ...\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual tests\n",
    "\n",
    "Pass the example texts from the repo description to pipeline.predict() and play around with new texts to get a feeling for how your model determines a sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your pipeline to create class predictions for the three example texts given in the readme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
