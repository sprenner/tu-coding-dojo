{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import necessary libraries\n",
    "\n",
    "Import `pandas as pd`, `numpy as np` and `seaborn as sns`\n",
    "Furthermore, import `Pipeline` from `sklearn.pipeline`, `RandomForestClassifier` from `sklearn.ensemble` and `train_test_split` from `sklearn.model_selection`.\n",
    "\n",
    "Import `accuracy_score`, `f1_score`, `precision_score`, `hamming_loss` and `confusion_matrix` from `sklearn.metrics`. \n",
    "\n",
    "Finally, import `CountVectorizer` and `TfidfTransformer` from `sklearn.feature_extraction.text` and `pplot_cm` from `conf_matrix` (this script should be in your local repo) and `matplotlib.pyplot` as `plt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n",
    "Load your previously saved csv dataframe using pandas' `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot label frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the seaborn color palette to \"deep\" using `sns.set()`.\n",
    "Then, plot the label frequencies using `sns.countplot()` on the column \"sentiment\" (or what ever you have called it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(...)\n",
    "...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load stopwords\n",
    "\n",
    "Use stop words to remove less-meaningful words. The logic of removing stop words has to do with the fact that these words don't carry a lot of meaning, and they appear a lot in most text. We have provided you with a list of common German stopwords ('data/stopwords_german.txt'). Import the packages `io` and `unidecode` first, then use `io.open()` and `readlines()` to save the words contained in the .txt file to a list. \n",
    "\n",
    "Call the python string function `strip()` to remove newline characters (`\\n`) and unidecode's `unidecode()` on every element in the resulting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also add your own stopwords in this step using append()\n",
    "...\n",
    "\n",
    "stopwords = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data for training\n",
    "\n",
    "To train and evaluate the model, we split the data into a training set and a test set using `train_test_split()`, the arguments  being the text column, the label/sentiment column, a test set size (`test_size=0.1` for 10%, `test_size=0.3` for 30%, etc.) and a integer of your choice as random_state.\n",
    "\n",
    "You can then call `.shape` on the resulting sets to see their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up ML pipeline\n",
    "\n",
    "Instantiate a pipeline by adding 3 steps: a `CountVectorizer()` `'vect'`, a `TfidfTransformer()` `'tfidf'` and a `RandomForestClassifier()` `'rf'`.\n",
    "\n",
    "The [Countvectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) helps us to create numerical values from text by counting the inherent tokens. Pass `analyzer='word'`, `strip_accents='unicode'` and `lowercase=True`. Pass your list of stopwords as `stop_words`.\n",
    "\n",
    "The arguments for the `TfidfTransformer` are `use_idf=True` and `smooth_idf=True`.\n",
    "\n",
    "Fit your pipeline to the training data by calling `fit()` on the pipeline object and passing the training texts and training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'vect',\n",
    "        ...\n",
    "    ),\n",
    "    (\n",
    "        'tfidf',\n",
    "        ...\n",
    "    ),\n",
    "    (\n",
    "        'rf',\n",
    "        ...\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pipeline to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score model\n",
    "\n",
    "We have provided you with a function to score your model using the test texts and labels. In case of encoding issues calling `.values.astype('U')` on the texts before passing them to your pipeline might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(true, pred):\n",
    "    print('Accuracy:', accuracy_score(true, pred))\n",
    "    print('F1:', f1_score(true, pred, average='weighted'))\n",
    "    print('Precision:', precision_score(true, pred, average='weighted'))\n",
    "    print('Hamming loss', hamming_loss(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot confusion matrix\n",
    "\n",
    "To quickly plot a confusion matrix, use the provided function pplot_cm and pass the same arguments as with `score_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a confucion matrix to visualize true positives, true negatives, ...\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual tests\n",
    "\n",
    "Pass the example texts from the repo description to `pipeline.predict()` and play around with new texts to get a feeling for how your model determines a sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your pipeline to create class predictions for the three example texts given in the readme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
