{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick note about Jupyter cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are editing a cell in Jupyter notebook, you need to re-run the cell by pressing `<Shift> + <Enter>`. This will allow changes you made to be available to other cells.\n",
    "\n",
    "Use `<Enter>` to make new lines inside a cell you are editing.\n",
    "\n",
    "### Code cells\n",
    "Re-running will execute any statements you have written. To edit an existing code cell, click on it.\n",
    "\n",
    "### Markdown cells\n",
    "Re-running will render the markdown text. To edit an existing markdown cell, double-click on it.\n",
    "\n",
    "\n",
    "### Common Jupyter operations\n",
    "\n",
    "**Inserting and removing cells**\n",
    "\n",
    "Use the \"plus sign\" icon to insert a cell below the currently selected cell\n",
    "Use \"Insert\" -> \"Insert Cell Above\" from the menu to insert above\n",
    "\n",
    "**Clear the output of all cells**\n",
    "\n",
    "Use \"Kernel\" -> \"Restart\" from the menu to restart the kernel\n",
    "click on \"clear all outputs & restart\" to have all the output cleared\n",
    "\n",
    "**Show function signature**\n",
    "\n",
    "Start typing function and hit `<Shift> + <Tab>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## import necessary libraries\n",
    "\n",
    "Import the following packages: `pandas as pd`, `csv`, `nltk` and `matplotlib.pyplot as plt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n",
    "As we have done the step of collecting some sample data for you already, you only have to load the data into a pandas dataframe using the method `pd.read_csv()`. Typing a variable name into a jupyter cell and running it, shows you the current content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect and clean data\n",
    "\n",
    "The dataset contains several entries of messages that have been deleted by the user after posting them, use pandas' `str.contains()` or any other method like `loc` to remove all rows that represent a message not accessibly anymore (\"Not Available\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns we are most interested in are \"text\" and \"sentiment\". Use pandas' `groupby()` method in combination with `count()` to get a first notion about the distribution of our labels. \n",
    "\n",
    "Drop the rest of the columns to retain a dataframe with the two columns \"text\" and \"sentiment\".\n",
    "\n",
    "Use the pandas function `str.replace()` to get rid of [twitter handles](https://www.urbandictionary.com/define.php?term=twitter%20handle) (hint: use regular expressions with `r'my_regex'` as the first argument `in str.replace()`).\n",
    "\n",
    "**Advanced**\n",
    "- Get rid of links. \n",
    "- Inspect the rest of the columns and keep some if they might contain information relevant to our prediction at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create single string to count word frequencies\n",
    "\n",
    "In order to visualize word frequencies, we will concatenate all messages to create one long string containing all words present in these messages. \n",
    "\n",
    "Use `str.cat()` with `sep=' '` on the column 'text' to create one string containing all messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tweets = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass merged_tweets to the `nltk` method `word_tokenize()` to create a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tweets_tokens = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use matplotlib to plot token frequencies. Set the matplotlib figure size to `(15, 8)` in order to create a larger plot area. \n",
    "Pass `merged_tweets_tokens` to `nltk.FreqDist()`, save the result as `fd` and call `fd.plot()` with `(50,cumulative=False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot token frequencies\n",
    "plt.figure(figsize=(.., ..))  \n",
    "\n",
    "fd = nltk. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pandas `to_csv()` method to save your dataframe as a .csv file. Name it \"training_data_tweets.csv\", set `encoding='utf-8'`, use `quoting=csv.QUOTE_ALL`, `header=False` and `index=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe in a format you can easily import in the following notebook\n",
    "tweets..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
